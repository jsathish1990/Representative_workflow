{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720306ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sathish\n",
      "[nltk_data]     Jayaraman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sathish\n",
      "[nltk_data]     Jayaraman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sathish\n",
      "[nltk_data]     Jayaraman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sathish\n",
      "[nltk_data]     Jayaraman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã¯\n",
      "['Metamorphosis ', 25910]\n"
     ]
    }
   ],
   "source": [
    "# Reference https://www.datacamp.com/community/tutorials/web-scraping-python-nlp\n",
    "# https://stackoverflow.com/questions/46271528/counting-words-inside-a-webpage/46473499\n",
    "# extract adjectives from text\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt') #need to download this for the English sentence tokenizer files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import numpy as np\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "#this splits up punctuation\n",
    "# test = \"\"\"Sample text.\"\"\"\n",
    "# tokens = nltk.word_tokenize(test)\n",
    "# print(tokens)\n",
    "\n",
    "# ts = nltk.sent_tokenize(test)\n",
    "# print(ts)\n",
    "# ns = len(ts)\n",
    "\n",
    "\n",
    "r = requests.get(\"https://www.gutenberg.org/files/5200/5200-0.txt\")\n",
    "st = BeautifulSoup(r.text, \"html5lib\")\n",
    "type(st)\n",
    "text = st.get_text()\n",
    "soup = BeautifulSoup(r.content)\n",
    "text_p = (''.join(s.findAll(text=True))for s in st.findAll('p'))\n",
    "# def preprocess_text(text):\n",
    "tokeniser = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokeniser.tokenize(text)\n",
    "# word_count = set()\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens[0])\n",
    "# print(pos_tag(tokens))\n",
    "word = set()\n",
    "words = tokens\n",
    "Metamorphosis = len(tokens)\n",
    "word.add(Metamorphosis)\n",
    "word_count = [\"Metamorphosis \",len(tokens)]\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281729e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
